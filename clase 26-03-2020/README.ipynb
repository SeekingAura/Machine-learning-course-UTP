{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo -> es el sistema o el modo en que va clasificar\n",
    "\n",
    "# Definiciones\n",
    "* **Objetivo**: Tomar un vector de entrada, **x** y asignar a una de K clases $C_k$ para $k=1, \\dots, K$\n",
    "* **Espacio de entrada** Se divide en regiones de decisión $R_k$ en donde cada area tiene una clasificación \n",
    "* **Líneas o superficies de decisión:** Separan las regiones de decisiones\n",
    "\n",
    "Unas metodologias se encargan en identificar regiones o otras se encargan de definir las fronteras de decisión. Las fronteras y areas estna dadas en 2D, 3D y N dimenciones\n",
    "\n",
    "## Modelo lineal\n",
    "* Las superficies de decisión son funciones lineales de **w** \n",
    "* **w** controla la inclinación de la recta y el itnercepto para 2d se suele utilizar clasificacadores del tipo $y=wx$\n",
    "* Las superficies están definidas por hiperplanos de dimensión D-1, en un espacio de D dimensiones... Los hiperplanos permiten proyectar los puntos a las idferentes dimnesione spara lelvarlo a un espacio de represetnación del modelo a realizar (en este caso dimensión 2)\n",
    "* Si los datos se pueden separar linealmente por una superficie de decisión lineal, se dice que los datos son linealmente separables.\n",
    "\n",
    "En algunos casos de clasificación pueden ser transformados usando funciones base. Los cmabios de dimensión para proytectarlos en un hiperplano, recta u otra cosa\n",
    "\n",
    "\n",
    "## Mas definiciones\n",
    "* En regresión $t_n$ representaba un número real asociado a al entrada $x_n$\n",
    "* En la clasificación, $t_n$ representa un vecotr, en condicición 1 de K... 1 de K o one encode tiene una lista de clasificación en donde determina de forma binaria su clasificación con 1 y ceros por ejemplo si es la dimensión de t es 3 seria \\[1 0 0\\] o \\[0 1 0\\] y asi.\n",
    "* Tres enfoques al problema de clasificación\n",
    "    * Funciones discriminantes\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Función discriminante\n",
    "Llevar un dato vectorial X a un valor k\n",
    "\n",
    "* Función $y(\\textbf{x}): \\textbf{x} \\rightarrow k, k \\in {1,...,K}$\n",
    "* **w** es el vector de pesos, y $w_0$ es la tendencia\n",
    "* $\\textbf{x} \\in C_1, si y(\\textbf{x})>0$ De lo contrario **x** $\\in C_2$\n",
    "* La linea de decisión o superficie de decisión es $y(\\textbf{x})>0$\n",
    "* El vector **w** es ortogonal a la superficie de decisión... Esta permite establecer o detemrinar por donde va pasar la frontera de decisión\n",
    "\n",
    "Los valores donde son 0 la función es los que se dan sobre la recta o bien la función como tal\n",
    "\n",
    "## Función discriminante 2\n",
    "Distancia de $y(\\textbf{x})$ al origen: $- w_0 /||w||$\n",
    "\n",
    "Distancia de un punto **x** a $y(\\textbf{x}): y(\\textbf{x})/||w||$\n",
    "\n",
    "$\\frac{w^\\top x}{||w||}$\n",
    "Con el intercepto se puede saber si la recta está por por encima o por debajo\n",
    "\n",
    "$\\frac{-w}{||w||}$ -> Inbtercepto\n",
    "\n",
    "Si la proyección de dos vector son perpendiculares usele presentar propiedad de ortogonalidad, me permite determinar el tema de fronteras de decisión\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Múltiples clases\n",
    "Construir un clasificador de K clases a partir de clasificación de 2 clases\n",
    "\n",
    "### Modelos de predicción a razón de 1 contra todos\n",
    "Para establecer en que región se está se debe verificar los valores de los $y_i$ que este presente de acuerdo a las parejas de clase que haya será la cantidad de lineas a lanzar\n",
    "\n",
    "### Modelos de clasificación 1 contra 1\n",
    "Es utilizar tantas regiones como pares de clasificadores haya\n",
    "\n",
    "## Multiples clases 2\n",
    "* Solución: Discriminante de K clases con K funciones lineales\n",
    "Las superficies dadas\n",
    "\n",
    "$y_k(\\textbf{x})=\\textbf{w}_k \\textbf{x} + w_k0$\n",
    "\n",
    "## Multiples clases 3\n",
    "* Sean $\\textbf{x}_A , \\textbf{x}_B \\in R_k$\n",
    "\n",
    "**Convexo:** Dado dos puntos se traza un segmento de recta, si se puede colocar todos los puntos que hay entre el punto **a** y el punto **b** en la misma región región de clasificación es convexo\n",
    "\n",
    "Los valores de las fronteras son dadas en un vector donde indica que tan lejos se está de cada región por ejemplo este estaria muy alejado de la región 3 \\[1 3 10 \\]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minimos cuadradados\n",
    "* Cada clase $C_k$ se describe por su propio modelo lineal\n",
    "\n",
    "$y_k(\\textbf{x})=\\textbf{w}_k \\textbf{x} + w_{k0}$\n",
    "\n",
    "Esta matriz que se establece de multiples salidas K tendrán una matrix por un vector donde los w indican los pesos que tiene cada parametro\n",
    "\n",
    "## Minimos cuadrados 2\n",
    "* Sea un conjunto de entrenamiento $\\{\\textbf{x}_n, \\textbf{t}_n\\}^N _{n=1}$ -> $R^D$ y $R^k$ Datos\n",
    "* La matrix **T** tiene vectores fila $\\textbf{t}^\\top _n$, y la matriz **X*** vectores fila $\\tilde{x}_n$\n",
    "* La función de error cuadrático está dada como ...\n",
    "\n",
    "\n",
    "Los erroes de neustro interes son los de la diagonal ya que cada uno indica cuanto error tiene una de las clases respecto a los demas (los errores cuadraticos). si se suma todos los errores (la diagonal de la matriz o la traza d ela matriz) se obtiene el error total.\n",
    "\n",
    "La idea es minimizar el error, El errortotal es equivalente a la seudoinversa de las entradas por las salidas esperadas -> $\\tilde{X}T$.\n",
    "\n",
    "El W de los minimos cuadrados es multiplicado con lso datos\n",
    "\n",
    "W es el modelo\n",
    "\n",
    "$W_{MSE}=pseudoinvert(X)T$\n",
    "\n",
    "pseudoinversa -> Permite hacer inversiones así no se cumplan las reglas de la inversa haciendo que se invierta lo que pueda invertirse\n",
    "\n",
    "* Minimizando e igualando a cero se obtiene el W mse\n",
    "\n",
    "N muestras sobre las K rectas.\n",
    "\n",
    "Debe tomarse el valor de $x*w$ que sea mayor del vector de valores con pesos ya uqe con eso garantiza que el dato si o si va tener pertenencia a esa región ( a mayor valor de un espacio, mayor pertenecia a ese espacio)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minimos cuadrados invoncenientes\n",
    "* Las lineas d eclasifican sean igual al de la predicción del modelo (la frontera)\n",
    "* Si la región presenta diferentes \"cliuusters\" o bien diferentes areas para clasificación hace que la clasificación no sea correcta y clasifique mal para el rango\n",
    "* En modelos de 3 clases  si se hace por minimo cuadrados tratará de construir una frontera entre todos los datos y en algunos casos puede generar fronteras que no existen asi como en el caso de 3 entrege 4 areas\n",
    "\n",
    "En caso de que no funciona el método de clasificación se debe cambiar de metodo.\n",
    "\n",
    "Cabe recordar que los datos deben trabajrse como vengan por que si no serán alterados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analisis discriminante de Gisher\n",
    "Linear Discriminant analisis\n",
    "\n",
    "* La idea es proyectar los datos a un espacio de menor dimensionalidad donde la clasificación sea mas sencilla\n",
    "* sea $\\textbf{x} \\in R^D$\n",
    "* Se proyecta a una dimensión usando \n",
    "\n",
    "$y=\\textbf{w}^\\top \\textbf{x}$\n",
    "\n",
    "* Se establece un umbral $y_0$ y se se clasifica un nuevo punto como de la clase $C_1$ si $y>=y_0$... por ejemplo que si un valor es mayor que cierto valor tiene una clasificación y si es menor a cierto vlaor tiene otra clasificación\n",
    "\n",
    "\n",
    "## graficas\n",
    "\n",
    "Los puntos de una grafica son proyectadas y se realiza un histograma, en el histograma estan los valores y de la clase que se encuentren  (clasificados por color)\n",
    "\n",
    "Hay un problema que se peude dar y es que algunos valores se pueden superponer en la clasificación que de el histograma los datos presentan varianzas MUY grandes y por eso se combinan. Lo ideal es que las varianzas sean \"pequeñas\". La idea es minimizar la varianz que tiene las distancias entre los valores que tiene el espacio luego de una proyección\n",
    "\n",
    "\n",
    "## Analisis discriminante de fiesher 2\n",
    "* Sea un problema biclase, con vectores de media\n",
    "\n",
    "\n",
    "* Una medida de la separación entre las clases es\n",
    "\n",
    "## Analisis discriminante de fiesher 3\n",
    "* No solo se queire maximizar la distancia entre medidas, si no qeu tambien minimizar la **variabildiad** de las muiestrras de cada clase\n",
    "\n",
    "## Analisis discriminante de fiesher 4\n",
    "* El criterio de Fisher se define como el radio de la varianza entre clases sobre la varianza intraclase\n",
    "\n",
    "Mediante el coheficiente de Reyly se debe maximizar las distnacias y minimizar las varianzas\n",
    "\n",
    "$j(\\textbf{w})=\\frac{(m_2 - m_1)^2}{s^2 _1 + s^2 _2}$\n",
    "\n",
    "* Haciendo los cambios apropiados se tiene un nuevo J(w)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "$s_B$ Es una matrix - > covarianza entre clases, **between** -> Maximizar, esta depende de los centros\n",
    "\n",
    "$s_w$ -> La suma de las covarianzas de cada clase dentro de calsa clase **with in** -> Minimizar, esta depende de las covarianzas\n",
    "\n",
    "La varianza en el espacio proyectado es\n",
    "\n",
    "$w^\\top \\sum _k w=s^2 _k$\n",
    "\n",
    "\n",
    "## Análisis discriminante de fisher 5\n",
    "* Se hace el proceso para maximizar a j(w) pmediante derivadas e igualando a cero\n",
    "\n",
    "* Lo que importa de **w** es su dirección, no su magnitud\n",
    "* Por lo tanto los escalares $\\textbf{w}^top\\textbf{S}_B\\textbf{w}$ y $\\textbf{w}^\\top S_w \\textbf{w}$ se pueden omitir por que para que logre ser cero debe tender a infinito\n",
    "\n",
    "Se presenta en el proceso de maximización (la derivada) generalized eigenvalues\n",
    "\n",
    "* Ademas $S_B w$ está siempre en la dirección de $m_2 - m_1$\n",
    "* Premultiplicando por $S^{-1} _w$ se encuentra que\n",
    "\n",
    "\n",
    "Los valores propios están dados por el coeficiente de **Rayleigh** \n",
    "\n",
    "El coeficiente de fisher me dice que tan dificil es despejar o alejar o ditanciar estos valores\n",
    "\n",
    "\n",
    "\n",
    "En la proceso de \"despeje\" los escalares peuden ser movidos de un lado a otro multiplicar y dividir sin problema asi tengan cruzado vectores o matrices\n",
    "\n",
    "\n",
    "\n",
    "El proceso es en si calcular los eigenvalues de forma generalizada donde se encontrara el vector **w** de pesos y los eigenvalues que entrega lo que tan dificil es despejar o alejar la distancia.\n",
    "\n",
    "\n",
    "Los rangos de clasificación se deben obtener mediante las medias proyectadas de cada clase\n",
    "$y_0 = \\frac{m_1 + m_2}{2}$\n",
    "\n",
    "el umbral de la clase es dado como un valor escalar donde establece la mitad del rango de vlaores en una clase\n",
    "\n",
    "\n",
    "Clasificación: es lo que se resuelve\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
